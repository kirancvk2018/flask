{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f2339383",
      "metadata": {
        "id": "f2339383"
      },
      "source": [
        "# Exercise 1: Gradebook Analyzer (NumPy-only)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d7f6af6",
      "metadata": {
        "id": "1d7f6af6"
      },
      "source": [
        "## Problem Statement\n",
        "Given a scores matrix of shape `(num_students, num_assignments)`, compute:\n",
        "1. Per-student average score and rank students.\n",
        "2. Per-assignment mean and standard deviation.\n",
        "3. A **z-score curve** per student (normalize each student's vector) and a **global curve** (normalize across all scores).\n",
        "4. A simple grade curve to target mean=75 and std=10 (vectorized).\n",
        "5. Compare vectorized per-assignment means with a naive Python loop to see speedup.\n",
        "\n",
        "**Constraints:** Use only NumPy. No pandas / scikit-learn."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e60ee078",
      "metadata": {
        "id": "e60ee078"
      },
      "source": [
        "## Approach\n",
        "- Create synthetic scores with a realistic distribution (clipped normal 0..100).\n",
        "- Use axis-wise reductions (`mean`, `std`), broadcasting for z-scores, and `argsort` for ranking.\n",
        "- For performance, compare `scores.mean(axis=0)` against a manual Python loop.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f333da",
      "metadata": {
        "id": "e1f333da"
      },
      "source": [
        "## Deliverables\n",
        "- Printed per-assignment stats, top-5 students with averages, and timing comparison.\n",
        "- Arrays: `student_avg`, `assign_mean`, `assign_std`, `z_per_student`, `z_global`, `curved_scores`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "772e0366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "772e0366",
        "outputId": "46cfa260-515a-471c-d42d-9f99eb4c9eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-assignment mean (first 5): [81.13 68.75 66.54 65.3  62.05]\n",
            "Per-assignment std  (first 5): [13.55 15.78 14.49 15.74 15.37]\n",
            "\n",
            "Top 5 students by average:\n",
            "  #1: student 210  avg=93.02\n",
            "  #2: student 436  avg=91.86\n",
            "  #3: student 312  avg=91.72\n",
            "  #4: student 107  avg=91.57\n",
            "  #5: student 223  avg=91.27\n",
            "\n",
            "Timing:\n",
            "  Vectorized mean: 0.000197 s\n",
            "  Loop mean:       0.002300 s\n",
            "  Speedup:         11.7x\n",
            "\n",
            "Max abs diff (vec vs loop): 5.7579040529276426e-05\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from time import perf_counter\n",
        "\n",
        "# ----- A) Synthetic data -----\n",
        "rng = np.random.default_rng(123)\n",
        "num_students = 500\n",
        "num_assignments = 12\n",
        "\n",
        "# base ability per student + assignment difficulty + noise\n",
        "ability = rng.normal(0.0, 10.0, size=(num_students, 1))           # student effect\n",
        "difficulty = rng.normal(0.0, 5.0, size=(1, num_assignments))       # assignment effect\n",
        "noise = rng.normal(70.0, 12.0, size=(num_students, num_assignments))# general level\n",
        "\n",
        "scores = ability + noise - difficulty\n",
        "scores = np.clip(scores, 0, 100).astype(np.float32)\n",
        "\n",
        "# ----- B) Core metrics -----\n",
        "student_avg = scores.mean(axis=1)                      # per-student average\n",
        "assign_mean = scores.mean(axis=0)                      # per-assignment mean\n",
        "assign_std = scores.std(axis=0, ddof=0)                # population std per assignment\n",
        "\n",
        "# z-score per student vector (center each student's row)\n",
        "row_mean = scores.mean(axis=1, keepdims=True)\n",
        "row_std = scores.std(axis=1, ddof=0, keepdims=True)\n",
        "z_per_student = np.divide(scores - row_mean, row_std, out=np.zeros_like(scores), where=row_std>0)\n",
        "\n",
        "# global z-score across all entries\n",
        "global_mean = scores.mean()\n",
        "global_std = scores.std(ddof=0)\n",
        "z_global = (scores - global_mean) / (global_std + 1e-12)\n",
        "\n",
        "# Curve to target mean=75, std=10 (global)\n",
        "target_mean, target_std = 75.0, 10.0\n",
        "curved_scores = (z_global * target_std + target_mean).astype(np.float32)\n",
        "curved_scores = np.clip(curved_scores, 0, 100)\n",
        "\n",
        "# ----- C) Ranking -----\n",
        "top5_idx = np.argsort(student_avg)[-5:][::-1]\n",
        "\n",
        "# ----- D) Performance comparison -----\n",
        "t0 = perf_counter()\n",
        "means_vec = scores.mean(axis=0)\n",
        "t1 = perf_counter()\n",
        "\n",
        "t2 = perf_counter()\n",
        "means_loop = np.zeros(num_assignments, dtype=np.float64)\n",
        "for j in range(num_assignments):\n",
        "    s = 0.0\n",
        "    for i in range(num_students):\n",
        "        s += float(scores[i, j])\n",
        "    means_loop[j] = s / num_students\n",
        "t3 = perf_counter()\n",
        "\n",
        "# ----- E) Results -----\n",
        "print('Per-assignment mean (first 5):', np.round(assign_mean[:5], 2))\n",
        "print('Per-assignment std  (first 5):', np.round(assign_std[:5], 2))\n",
        "print('\\nTop 5 students by average:')\n",
        "for rank, idx in enumerate(top5_idx, 1):\n",
        "    print(f'  #{rank}: student {idx:3d}  avg={student_avg[idx]:.2f}')\n",
        "\n",
        "print('\\nTiming:')\n",
        "print(f'  Vectorized mean: {(t1 - t0):.6f} s')\n",
        "print(f'  Loop mean:       {(t3 - t2):.6f} s')\n",
        "print(f'  Speedup:         {(t3 - t2)/(t1 - t0 + 1e-12):.1f}x')\n",
        "\n",
        "# Sanity check equality\n",
        "print('\\nMax abs diff (vec vs loop):', float(np.max(np.abs(means_vec - means_loop))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a clean, thorough walkthrough of what each block does, with shapes and NumPy concepts called out.\n",
        "\n",
        "# Imports\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "from time import perf_counter\n",
        "```\n",
        "\n",
        "* `numpy` for vectorized array math.\n",
        "* `perf_counter()` is a high-resolution timer for benchmarking small code sections.\n",
        "\n",
        "---\n",
        "\n",
        "# A) Synthetic data\n",
        "\n",
        "```python\n",
        "rng = np.random.default_rng(123)\n",
        "num_students = 500\n",
        "num_assignments = 12\n",
        "```\n",
        "\n",
        "* `default_rng(123)` creates a reproducible random generator.\n",
        "* We’ll model a 500×12 “gradebook” (students × assignments).\n",
        "\n",
        "```python\n",
        "# base ability per student + assignment difficulty + noise\n",
        "ability = rng.normal(0.0, 10.0, size=(num_students, 1))            # (500, 1)\n",
        "difficulty = rng.normal(0.0, 5.0, size=(1, num_assignments))        # (1, 12)\n",
        "noise = rng.normal(70.0, 12.0, size=(num_students, num_assignments))# (500, 12)\n",
        "```\n",
        "\n",
        "* Three components:\n",
        "\n",
        "  * **ability**: per-student offset (column vector). Same value broadcast across that student’s 12 assignments.\n",
        "  * **difficulty**: per-assignment offset (row vector). Same value broadcast across all students for that assignment.\n",
        "  * **noise**: baseline around \\~70 with some spread (realistic grades).\n",
        "\n",
        "```python\n",
        "scores = ability + noise - difficulty    # broadcasting → (500, 12)\n",
        "scores = np.clip(scores, 0, 100).astype(np.float32)\n",
        "```\n",
        "\n",
        "* **Broadcasting** combines shapes `(500,1) + (500,12) - (1,12)` → `(500,12)`.\n",
        "* Clip to `[0, 100]` like real scores; store as `float32` (saves memory, fast).\n",
        "\n",
        "---\n",
        "\n",
        "# B) Core metrics\n",
        "\n",
        "```python\n",
        "student_avg = scores.mean(axis=1)        # (500,) mean across assignments\n",
        "assign_mean = scores.mean(axis=0)        # (12,)  mean across students\n",
        "assign_std  = scores.std(axis=0, ddof=0) # population std per assignment\n",
        "```\n",
        "\n",
        "* `axis=1`: reduce rows → per-student average.\n",
        "* `axis=0`: reduce columns → per-assignment statistics.\n",
        "* `ddof=0` means **population** std (not sample). (Sample std would use `ddof=1`.)\n",
        "\n",
        "---\n",
        "\n",
        "# Row-wise (per-student) z-scores\n",
        "\n",
        "```python\n",
        "row_mean = scores.mean(axis=1, keepdims=True)           # (500,1)\n",
        "row_std  = scores.std(axis=1, ddof=0, keepdims=True)    # (500,1)\n",
        "z_per_student = np.divide(\n",
        "    scores - row_mean, row_std,\n",
        "    out=np.zeros_like(scores),\n",
        "    where=row_std > 0\n",
        ")\n",
        "```\n",
        "\n",
        "* Normalize each student’s vector to mean 0, std 1.\n",
        "* `keepdims=True` keeps shapes compatible for broadcasting `(500,12) - (500,1)`.\n",
        "* `np.divide(..., where=row_std>0)` avoids divide-by-zero if a student’s scores are all identical; those rows become zeros via `out=`.\n",
        "\n",
        "---\n",
        "\n",
        "# Global z-scores\n",
        "\n",
        "```python\n",
        "global_mean = scores.mean()            # scalar\n",
        "global_std  = scores.std(ddof=0)       # scalar\n",
        "z_global = (scores - global_mean) / (global_std + 1e-12)\n",
        "```\n",
        "\n",
        "* Normalize **all** scores using the single global mean/std (different from row-wise). Tiny `1e-12` avoids any divide-by-zero edge case.\n",
        "\n",
        "---\n",
        "\n",
        "# Curving to a target scale\n",
        "\n",
        "```python\n",
        "target_mean, target_std = 75.0, 10.0\n",
        "curved_scores = (z_global * target_std + target_mean).astype(np.float32)\n",
        "curved_scores = np.clip(curved_scores, 0, 100)\n",
        "```\n",
        "\n",
        "* Standard curving: convert z-scores to a distribution with desired mean/std, then clip to the scoring range.\n",
        "\n",
        "---\n",
        "\n",
        "# Ranking\n",
        "\n",
        "```python\n",
        "top5_idx = np.argsort(student_avg)[-5:][::-1]\n",
        "```\n",
        "\n",
        "* `argsort` returns indices sorted by value (ascending). Take last 5 (largest), then reverse → **top-5 students** by average.\n",
        "\n",
        "---\n",
        "\n",
        "# Performance comparison\n",
        "\n",
        "```python\n",
        "t0 = perf_counter()\n",
        "means_vec = scores.mean(axis=0)     # vectorized mean per assignment\n",
        "t1 = perf_counter()\n",
        "```\n",
        "\n",
        "* Fast, compiled path: one call reduces all 500 rows for each of the 12 columns.\n",
        "\n",
        "```python\n",
        "t2 = perf_counter()\n",
        "means_loop = np.zeros(num_assignments, dtype=np.float64)\n",
        "for j in range(num_assignments):\n",
        "    s = 0.0\n",
        "    for i in range(num_students):\n",
        "        s += float(scores[i, j])\n",
        "    means_loop[j] = s / num_students\n",
        "t3 = perf_counter()\n",
        "```\n",
        "\n",
        "* Slow, pure-Python nested loops doing the same math. Same complexity on paper, but Python loop overhead dominates. Using `float64` here avoids extra rounding in the manual accumulator.\n",
        "\n",
        "---\n",
        "\n",
        "# Results\n",
        "\n",
        "```python\n",
        "print('Per-assignment mean (first 5):', np.round(assign_mean[:5], 2))\n",
        "print('Per-assignment std  (first 5):', np.round(assign_std[:5], 2))\n",
        "\n",
        "print('\\nTop 5 students by average:')\n",
        "for rank, idx in enumerate(top5_idx, 1):\n",
        "    print(f'  #{rank}: student {idx:3d}  avg={student_avg[idx]:.2f}')\n",
        "```\n",
        "\n",
        "* Displays basic stats and the top-5 leaderboard.\n",
        "\n",
        "```python\n",
        "print('\\nTiming:')\n",
        "print(f'  Vectorized mean: {(t1 - t0):.6f} s')\n",
        "print(f'  Loop mean:       {(t3 - t2):.6f} s')\n",
        "print(f'  Speedup:         {(t3 - t2)/(t1 - t0 + 1e-12):.1f}x')\n",
        "```\n",
        "\n",
        "* Reports absolute times and speedup (loop / vectorized). The tiny epsilon avoids a zero-division if the vectorized path is extremely fast.\n",
        "\n",
        "```python\n",
        "print('\\nMax abs diff (vec vs loop):', float(np.max(np.abs(means_vec - means_loop))))\n",
        "```\n",
        "\n",
        "* **Sanity check**: the two methods should agree up to small floating-point differences (float32 vs float64 accumulation and order of summation).\n",
        "\n",
        "---\n",
        "\n",
        "## Key NumPy ideas used\n",
        "\n",
        "* **Broadcasting**: `(500,1)` and `(1,12)` expand to `(500,12)` automatically.\n",
        "* **Axis reductions**: `mean`/`std` along rows or columns with `axis`.\n",
        "* **Safe division**: `np.divide` with `where=` and `out=` to handle edge cases.\n",
        "* **Vectorization vs loops**: one call over whole arrays is much faster than Python loops.\n",
        "* **Dtypes**: `float32` for compact storage/speed; `float64` for accumulators to reduce rounding error (the code mixes responsibly).\n",
        "\n",
        "## Complexity (N = students, M = assignments)\n",
        "\n",
        "* Data creation & stats: `O(N*M)` in vectorized C; the nested Python loop also does `O(N*M)` work but is far slower due to interpreter overhead.\n"
      ],
      "metadata": {
        "id": "uJlPH_QXloa-"
      },
      "id": "uJlPH_QXloa-"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}